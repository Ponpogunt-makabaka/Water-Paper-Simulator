# main.py
"""
Optimized main entry point for research paper generation system.
Implements efficient execution with minimal token usage.
Fixed logging configuration to ensure proper file output.
"""

import os
import sys
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional

import config
from graph import create_app


def setup_langsmith():
    """Configure LangSmith tracing if enabled."""
    if config.LANGSMITH_TRACING.lower() == "true":
        os.environ["LANGCHAIN_TRACING_V2"] = "true"
        os.environ["LANGCHAIN_ENDPOINT"] = config.LANGSMITH_ENDPOINT
        os.environ["LANGCHAIN_API_KEY"] = config.LANGSMITH_API_KEY
        os.environ["LANGCHAIN_PROJECT"] = config.LANGSMITH_PROJECT
        print("‚úÖ LangSmith tracing enabled")
        print(f"   Project: {config.LANGSMITH_PROJECT}")
    else:
        print("‚ÑπÔ∏è LangSmith tracing disabled")


class OutputManager:
    """Manages output files and logging with improved configuration."""
    
    def __init__(self):
        self.output_dir = Path(config.OUTPUT_DIR)
        self.output_dir.mkdir(exist_ok=True)
        self.setup_logging()
        
    def setup_logging(self) -> None:
        """Configure comprehensive logging with file and console output."""
        log_file = self.output_dir / "workflow.log"
        
        # Clear existing handlers to avoid conflicts
        for handler in logging.root.handlers[:]:
            logging.root.removeHandler(handler)
        
        # Create formatters
        detailed_formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        
        simple_formatter = logging.Formatter(
            '%(asctime)s - %(levelname)s - %(message)s',
            datefmt='%H:%M:%S'
        )
        
        # Configure file handler
        file_handler = logging.FileHandler(log_file, mode='w', encoding='utf-8')
        file_handler.setLevel(logging.DEBUG)
        file_handler.setFormatter(detailed_formatter)
        
        # Configure console handler
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setLevel(logging.INFO)
        console_handler.setFormatter(simple_formatter)
        
        # Configure root logger
        logging.basicConfig(
            level=logging.DEBUG,
            handlers=[file_handler, console_handler],
            force=True  # Force reconfiguration
        )
        
        # Set specific logger levels
        logging.getLogger("httpx").setLevel(logging.WARNING)
        logging.getLogger("urllib3").setLevel(logging.WARNING)
        logging.getLogger("faiss").setLevel(logging.WARNING)
        
        self.logger = logging.getLogger(__name__)
        self.logger.info(f"Logging initialized. Log file: {log_file}")
        
        # Test log file writing
        try:
            with open(log_file, 'a', encoding='utf-8') as f:
                f.write(f"=== Workflow started at {datetime.now()} ===\n")
            self.logger.info("Log file test successful")
        except Exception as e:
            self.logger.error(f"Log file test failed: {e}")
    
    def save_paper(self, content: str) -> Path:
        """Save final paper with metadata."""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"paper_{timestamp}.txt"
        filepath = self.output_dir / filename
        
        # Add metadata header
        header = f"""# Research Paper Generated by AI System
# Generated: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
# Topic: {config.TOPIC}
# System: Water-Paper-Simulator

{'='*80}

"""
        
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(header + content)
        
        self.logger.info(f"Paper saved to: {filepath}")
        return filepath
    
    def save_state(self, state: Dict[str, Any]) -> None:
        """Save final state for debugging with detailed information."""
        filepath = self.output_dir / "final_state.txt"
        
        with open(filepath, "w", encoding="utf-8") as f:
            f.write("="*80 + "\n")
            f.write("FINAL WORKFLOW STATE SUMMARY\n")
            f.write("="*80 + "\n\n")
            f.write(f"Timestamp: {datetime.now()}\n")
            f.write(f"Topic: {config.TOPIC}\n\n")
            
            # Key metrics
            f.write("KEY METRICS:\n")
            f.write("-" * 40 + "\n")
            f.write(f"Revision Count: {state.get('revision_count', 'N/A')}\n")
            f.write(f"Workflow Status: {state.get('workflow_status', 'N/A')}\n")
            f.write(f"Draft Version: {state.get('draft_version', 'N/A')}\n")
            
            # Review scores if available
            if 'score_breadth' in state:
                f.write(f"Breadth Score: {state['score_breadth']:.3f}\n")
            if 'score_depth' in state:
                f.write(f"Depth Score: {state['score_depth']:.3f}\n")
            
            f.write("\n" + "="*80 + "\n")
            f.write("DETAILED STATE INFORMATION:\n")
            f.write("="*80 + "\n\n")
            
            for key, value in state.items():
                f.write(f"{key}:\n")
                f.write("-" * len(key) + "\n")
                
                if isinstance(value, str):
                    # Truncate long strings
                    if len(value) > 200:
                        f.write(f"{value[:200]}...\n")
                    else:
                        f.write(f"{value}\n")
                elif isinstance(value, (list, dict)):
                    f.write(f"{type(value).__name__} with {len(value)} items\n")
                else:
                    f.write(f"{value} ({type(value).__name__})\n")
                
                f.write("\n")
        
        self.logger.info(f"Final state saved to: {filepath}")
    
    def save_workflow_summary(self, success: bool, error_msg: str = None):
        """Save a summary of the workflow execution."""
        summary_file = self.output_dir / "workflow_summary.txt"
        
        with open(summary_file, "w", encoding="utf-8") as f:
            f.write("WORKFLOW EXECUTION SUMMARY\n")
            f.write("="*50 + "\n\n")
            f.write(f"Start Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"Topic: {config.TOPIC}\n")
            f.write(f"Status: {'SUCCESS' if success else 'FAILED'}\n")
            
            if error_msg:
                f.write(f"Error: {error_msg}\n")
            
            f.write(f"\nConfiguration:\n")
            f.write(f"- Model Provider: {config.MODEL_PROVIDER}\n")
            f.write(f"- Max Revisions: {config.MAX_REVISIONS}\n")
            f.write(f"- Embedding Model: {config.OLLAMA_EMBEDDING_MODEL}\n")
            
            # Check file existence
            files_created = []
            for file in self.output_dir.glob("*"):
                files_created.append(file.name)
            
            f.write(f"\nFiles Created: {len(files_created)}\n")
            for file in files_created:
                f.write(f"- {file}\n")


class ResearchRunner:
    """Main runner for research workflow with enhanced error handling."""
    
    def __init__(self):
        self.output = OutputManager()
        self.app = create_app()
        
    def run(self) -> bool:
        """
        Execute research workflow with comprehensive error handling.
        
        Returns:
            True if successful, False otherwise
        """
        try:
            # Initialize state
            initial_state = {
                "topic": config.TOPIC,
                "revision_count": 0,
                "draft_history": [],
                "workflow_status": "initialized"
            }
            
            self.output.logger.info(f"Starting research workflow for topic: {config.TOPIC}")
            self.output.logger.info(f"Configuration: Provider={config.MODEL_PROVIDER}, MaxRevisions={config.MAX_REVISIONS}")
            
            # Execute workflow
            self.output.logger.info("Invoking workflow application...")
            final_state = self.app.invoke(initial_state)
            
            # Check status
            workflow_status = final_state.get("workflow_status", "unknown")
            if workflow_status == "error":
                error_msg = final_state.get("error", "Unknown error occurred")
                self.output.logger.error(f"Workflow failed: {error_msg}")
                self.output.save_workflow_summary(False, error_msg)
                return False
            
            # Extract final paper
            final_paper = self._extract_paper(final_state)
            
            if final_paper:
                # Save paper
                filepath = self.output.save_paper(final_paper)
                
                # Display results
                self._display_results(filepath, final_paper, final_state)
                
                # Save state
                self.output.save_state(final_state)
                
                # Save summary
                self.output.save_workflow_summary(True)
                
                self.output.logger.info("Research workflow completed successfully")
                return True
            else:
                error_msg = "No paper content generated"
                self.output.logger.error(error_msg)
                self.output.save_workflow_summary(False, error_msg)
                return False
                
        except Exception as e:
            error_msg = f"Critical workflow error: {e}"
            self.output.logger.error(error_msg, exc_info=True)
            print(f"\n‚ùå Fatal error: {e}")
            self.output.save_workflow_summary(False, str(e))
            return False
    
    def _extract_paper(self, state: Dict[str, Any]) -> Optional[str]:
        """Extract final paper from state with improved logic."""
        self.output.logger.debug("Extracting paper from final state...")
        
        # Try current draft first
        if "current_draft" in state and state["current_draft"]:
            content = state["current_draft"]
            self.output.logger.info(f"Extracted current draft ({len(content)} characters)")
            return content
        
        # Try draft history
        if "draft_history" in state and state["draft_history"]:
            last_draft = state["draft_history"][-1]
            
            if isinstance(last_draft, str):
                self.output.logger.info(f"Extracted from draft history ({len(last_draft)} characters)")
                return last_draft
            elif hasattr(last_draft, "content"):
                content = last_draft.content
                self.output.logger.info(f"Extracted from draft object ({len(content)} characters)")
                return content
        
        self.output.logger.warning("No paper content found in state")
        return None
    
    def _display_results(self, filepath: Path, content: str, state: Dict[str, Any]) -> None:
        """Display completion message with comprehensive information."""
        print("\n" + "="*80)
        print("‚úÖ RESEARCH PAPER GENERATION COMPLETED")
        print("="*80)
        print(f"\nTopic: {config.TOPIC}")
        print(f"Paper saved to: {filepath}")
        print(f"Paper length: {len(content):,} characters")
        
        # Show revision info if available
        revision_count = state.get("revision_count", 0)
        if revision_count > 0:
            print(f"Revisions: {revision_count}")
        
        # Show review scores if available
        if 'score_breadth' in state:
            print(f"Breadth Score: {state['score_breadth']:.3f}")
        if 'score_depth' in state:
            print(f"Depth Score: {state['score_depth']:.3f}")
        
        print(f"\nPaper preview:")
        print("-" * 60)
        
        # Show first 300 characters
        preview = content[:300]
        if len(content) > 300:
            preview += "..."
        print(preview)
        
        print("-" * 60)
        print(f"\nAll outputs saved in: {self.output.output_dir}")


def main():
    """Main entry point with enhanced setup and error handling."""
    print("\n" + "="*80)
    print("AI-POWERED RESEARCH PAPER GENERATION SYSTEM")
    print("="*80)
    
    # Setup LangSmith if configured
    setup_langsmith()
    
    print(f"\nConfiguration Summary:")
    print(f"- Provider: {config.MODEL_PROVIDER}")
    print(f"- Embedding Model: {config.OLLAMA_EMBEDDING_MODEL}")
    print(f"- Max Revisions: {config.MAX_REVISIONS}")
    print(f"- Output Directory: {config.OUTPUT_DIR}")
    print(f"- Topic: {config.TOPIC[:60]}{'...' if len(config.TOPIC) > 60 else ''}")
    print("\nStarting workflow execution...\n")
    
    try:
        runner = ResearchRunner()
        success = runner.run()
        
        if success:
            print(f"\n‚úÖ SUCCESS! Check '{config.OUTPUT_DIR}' folder for all results.")
            print("üìÅ Generated files:")
            output_path = Path(config.OUTPUT_DIR)
            for file in sorted(output_path.glob("*")):
                print(f"   - {file.name}")
            sys.exit(0)
        else:
            print(f"\n‚ùå FAILED! Check '{config.OUTPUT_DIR}/workflow.log' for details.")
            sys.exit(1)
            
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è Interrupted by user.")
        sys.exit(1)
    except Exception as e:
        print(f"\nüí• Unexpected error: {e}")
        print(f"Check '{config.OUTPUT_DIR}/workflow.log' for details.")
        sys.exit(1)


if __name__ == "__main__":
    main()